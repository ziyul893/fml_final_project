{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/whimian/SVM-Image-Classification/blob/master/Image%20Classification%20using%20scikit-learn.ipynb\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(128, 128)):\n",
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\"\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []         # matrix storing resized images\n",
    "    flat_data = []      # flatten image information\n",
    "    target = []         # label of folders\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            img = skimage.io.imread(file)\n",
    "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "            images.append(img_resized)\n",
    "            target.append(i)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"Prime_FULL/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifier from HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class SVM:\n",
    "\n",
    "    def __init__(self, C = 1.0):\n",
    "        # C = error term\n",
    "        self.C = C\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "    ## question i\n",
    "    def hingeloss(self, w, b, x, y):\n",
    "        \"\"\"Function computes the hinge loss\"\"\"\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        w: ndarray of shape (D,)\n",
    "            1D numpy array representing the normal vector to the SVM hyperplane.\n",
    "\n",
    "        b: ndarray of shape (D,)\n",
    "            1D numpy array representing the vector that translates the SVM hyperplane.\n",
    "\n",
    "        X: ndarray of shape (N,D)\n",
    "            2D numpy array containing N training examples having D dimensions each.\n",
    "\n",
    "        Y: ndarray of shape (N,)\n",
    "            1D numpy array containing containing ground truth class information.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred: float\n",
    "            float containing the hinge loss.\n",
    "\n",
    "        \"\"\"\n",
    "        # hinge loss function / calculation\n",
    "        # regularization term\n",
    "        # partial derivative of L_hinge wrt w\n",
    "        loss = 0.5*norm(w,2)*norm(w,2)+self.C*np.sum(np.maximum(np.zeros(x.shape[0]),np.ones(x.shape[0])-y*((w)@np.transpose(x)-b*np.ones(x.shape[0]))),axis=1)\n",
    "        return float(loss)\n",
    "\n",
    "\n",
    "    def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
    "        # the number of features in X\n",
    "        number_of_features = X.shape[1]\n",
    "\n",
    "        # the number of Samples in X\n",
    "        number_of_samples = X.shape[0]\n",
    "\n",
    "        c = self.C\n",
    "\n",
    "        # creating ids from 0 to number_of_samples - 1\n",
    "        ids = np.arange(number_of_samples)\n",
    "\n",
    "        # shuffling the samples randomly\n",
    "        np.random.shuffle(ids)\n",
    "\n",
    "        # creating an array of zeros\n",
    "        w = np.zeros((1, number_of_features))\n",
    "        b = 0\n",
    "        losses = []\n",
    "\n",
    "        # gradient descent algorithm\n",
    "        for i in range(epochs):\n",
    "            # calculating the Hinge Loss\n",
    "            l = self.hingeloss(w, b, X, Y)\n",
    "       \n",
    "            # appending all losses\n",
    "            losses.append(l)\n",
    "\n",
    "            # starting from 0 to the number of samples with batch_size as interval\n",
    "            for batch_initial in range(0, number_of_samples, batch_size):\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "\n",
    "                for j in range(batch_initial, batch_initial+ batch_size):\n",
    "                    if j < number_of_samples:\n",
    "                        x = ids[j]\n",
    "                        ## question ii\n",
    "                        # calculating the gradients\n",
    "\n",
    "                        comp = Y[x]*(w @ X[x].T+b)\n",
    "                        if(1-comp >0):\n",
    "                          gradw +=  c *-Y[x]*X[x]\n",
    "                          gradb += c *-Y[x]\n",
    "                        else:\n",
    "                          gradw += 0\n",
    "                          gradb += 0\n",
    "\n",
    "              ## question iii\n",
    "              # updating weights and bias\n",
    "                w = w - learning_rate * w - learning_rate*gradw\n",
    "                b = b - learning_rate*gradb\n",
    "\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "        return self.w, self.b, losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        ## question iv\n",
    "        # prediction\n",
    "        \"\"\"Function predicts the output of the SVM\"\"\"\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: ndarray of shape (N,D)\n",
    "            2D numpy array containing N testing examples having D dimensions each.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        svm_prediction: ndarray of shape (N,)\n",
    "            The prediction of the SVM algorithm in the form of integers. (The \n",
    "            output should be an element of the set {1, -1}.)\n",
    "        \"\"\"\n",
    "        svm_prediction = np.zeros([X.shape[0],1])\n",
    "        for i in range(X.shape[0]):\n",
    "          svm_prediction[i]= 1 if w@(X[i].reshape(-1,1))+b>0 else -1\n",
    "        return svm_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Classification report for - \\n{}:\\n{}\\n\".format(\n",
    "    clf, metrics.classification_report(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
